{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "383f16eb",
   "metadata": {},
   "source": [
    "# PART I: Data Processing    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T03:02:00.445862740Z",
     "start_time": "2025-12-19T03:01:56.183665830Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env path: /home/k/miniforge3/envs/ml_py310/bin:/home/k/miniforge3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/snap/bin\n",
      "python version: 3.10.19 | packaged by conda-forge | (main, Oct 13 2025, 14:08:27) [GCC 14.3.0]\n",
      "torch version: 2.9.1\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import os, random, sys\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"env path: {os.getenv('PATH')}\")\n",
    "print(f\"python version: {sys.version}\")\n",
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff948668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of cat images: 12499\n",
      "Num of dog images: 12499\n"
     ]
    }
   ],
   "source": [
    "# reproducibility\n",
    "SEED = 0\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# data path\n",
    "DATA_PREFIX = Path(\"../data/PetImages\")\n",
    "CAT_PATH = DATA_PREFIX / \"Cat\"\n",
    "DOG_PATH = DATA_PREFIX / \"Dog\"\n",
    "\n",
    "# sort image paths\n",
    "cat_paths = sorted(str(p) for p in CAT_PATH.glob(\"*.jpg\"))\n",
    "dog_paths = sorted(str(p) for p in DOG_PATH.glob(\"*.jpg\"))\n",
    "print(f\"Num of cat images: {len(cat_paths)}\")\n",
    "print(f\"Num of dog images: {len(dog_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b5c0acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "# train/val/test 0.7/0.15/0.15\n",
    "TRAIN_TEMP_SPLIT = 0.7\n",
    "VAL_TEST_SPLIT = 0.5\n",
    "\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23276a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of valid cat images: 12499\n",
      "Num of valid dog images: 12499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/run/media/c_yikai/lab/app/mamba/envs/ml_py310/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:949: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    }
   ],
   "source": [
    "# filter images with PIL\n",
    "from PIL import Image\n",
    "from PIL.Image import UnidentifiedImageError\n",
    "\n",
    "# filter out corrupt files\n",
    "def filter_valid_images(paths : list[str]) -> list[str]:\n",
    "    valid_image_paths = []\n",
    "    for p in paths:\n",
    "        try:\n",
    "            with Image.open(p) as img:\n",
    "                img.verify()\n",
    "            valid_image_paths.append(p)\n",
    "        except UnidentifiedImageError as e1:\n",
    "            print(f\"Corrupted image: {p}\")\n",
    "        except Exception as e2:\n",
    "            print(\"IO or something else is wrong.\")\n",
    "            print(e2.args)\n",
    "    return valid_image_paths\n",
    "\n",
    "valid_cat_paths = filter_valid_images(cat_paths)\n",
    "valid_dog_paths = filter_valid_images(dog_paths)\n",
    "print(f\"Num of valid cat images: {len(valid_cat_paths)}\")\n",
    "print(f\"Num of valid dog images: {len(valid_dog_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "758bf2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of total samples: 24998\n",
      "Num of training samples: 17498\n",
      "Num of valuating samples: 3750\n",
      "Num of testing samples: 3750\n"
     ]
    }
   ],
   "source": [
    "# Train/Val/Test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cat_labels = [0] * len(valid_cat_paths)\n",
    "dog_labels = [1] * len(valid_dog_paths)\n",
    "\n",
    "X = np.array(valid_cat_paths + valid_dog_paths)\n",
    "y = np.array(cat_labels + dog_labels)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, train_size=TRAIN_TEMP_SPLIT, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, train_size=VAL_TEST_SPLIT, random_state=SEED, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Num of total samples: {len(X)}\\n\"\n",
    "    + f\"Num of training samples: {len(X_train)}\\n\"\n",
    "    + f\"Num of valuating samples: {len(X_val)}\\n\"\n",
    "    + f\"Num of testing samples: {len(X_test)}\"\n",
    "    )\n",
    "assert y_train.mean() == 0.5\n",
    "assert y_val.mean() == 0.5\n",
    "assert y_test.mean() == 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7bd844",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1508952994.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    img_bytes =\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# load images from paths\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0401e889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AlexNet', 'AlexNet_Weights', 'ConvNeXt', 'ConvNeXt_Base_Weights', 'ConvNeXt_Large_Weights', 'ConvNeXt_Small_Weights', 'ConvNeXt_Tiny_Weights', 'DenseNet', 'DenseNet121_Weights', 'DenseNet161_Weights', 'DenseNet169_Weights', 'DenseNet201_Weights', 'EfficientNet', 'EfficientNet_B0_Weights', 'EfficientNet_B1_Weights', 'EfficientNet_B2_Weights', 'EfficientNet_B3_Weights', 'EfficientNet_B4_Weights', 'EfficientNet_B5_Weights', 'EfficientNet_B6_Weights', 'EfficientNet_B7_Weights', 'EfficientNet_V2_L_Weights', 'EfficientNet_V2_M_Weights', 'EfficientNet_V2_S_Weights', 'GoogLeNet', 'GoogLeNetOutputs', 'GoogLeNet_Weights', 'Inception3', 'InceptionOutputs', 'Inception_V3_Weights', 'MNASNet', 'MNASNet0_5_Weights', 'MNASNet0_75_Weights', 'MNASNet1_0_Weights', 'MNASNet1_3_Weights', 'MaxVit', 'MaxVit_T_Weights', 'MobileNetV2', 'MobileNetV3', 'MobileNet_V2_Weights', 'MobileNet_V3_Large_Weights', 'MobileNet_V3_Small_Weights', 'RegNet', 'RegNet_X_16GF_Weights', 'RegNet_X_1_6GF_Weights', 'RegNet_X_32GF_Weights', 'RegNet_X_3_2GF_Weights', 'RegNet_X_400MF_Weights', 'RegNet_X_800MF_Weights', 'RegNet_X_8GF_Weights', 'RegNet_Y_128GF_Weights', 'RegNet_Y_16GF_Weights', 'RegNet_Y_1_6GF_Weights', 'RegNet_Y_32GF_Weights', 'RegNet_Y_3_2GF_Weights', 'RegNet_Y_400MF_Weights', 'RegNet_Y_800MF_Weights', 'RegNet_Y_8GF_Weights', 'ResNeXt101_32X8D_Weights', 'ResNeXt101_64X4D_Weights', 'ResNeXt50_32X4D_Weights', 'ResNet', 'ResNet101_Weights', 'ResNet152_Weights', 'ResNet18_Weights', 'ResNet34_Weights', 'ResNet50_Weights', 'ShuffleNetV2', 'ShuffleNet_V2_X0_5_Weights', 'ShuffleNet_V2_X1_0_Weights', 'ShuffleNet_V2_X1_5_Weights', 'ShuffleNet_V2_X2_0_Weights', 'SqueezeNet', 'SqueezeNet1_0_Weights', 'SqueezeNet1_1_Weights', 'SwinTransformer', 'Swin_B_Weights', 'Swin_S_Weights', 'Swin_T_Weights', 'Swin_V2_B_Weights', 'Swin_V2_S_Weights', 'Swin_V2_T_Weights', 'VGG', 'VGG11_BN_Weights', 'VGG11_Weights', 'VGG13_BN_Weights', 'VGG13_Weights', 'VGG16_BN_Weights', 'VGG16_Weights', 'VGG19_BN_Weights', 'VGG19_Weights', 'ViT_B_16_Weights', 'ViT_B_32_Weights', 'ViT_H_14_Weights', 'ViT_L_16_Weights', 'ViT_L_32_Weights', 'VisionTransformer', 'Weights', 'WeightsEnum', 'Wide_ResNet101_2_Weights', 'Wide_ResNet50_2_Weights', '_GoogLeNetOutputs', '_InceptionOutputs', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_api', '_meta', '_utils', 'alexnet', 'convnext', 'convnext_base', 'convnext_large', 'convnext_small', 'convnext_tiny', 'densenet', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'detection', 'efficientnet', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2', 'efficientnet_b3', 'efficientnet_b4', 'efficientnet_b5', 'efficientnet_b6', 'efficientnet_b7', 'efficientnet_v2_l', 'efficientnet_v2_m', 'efficientnet_v2_s', 'get_model', 'get_model_builder', 'get_model_weights', 'get_weight', 'googlenet', 'inception', 'inception_v3', 'list_models', 'maxvit', 'maxvit_t', 'mnasnet', 'mnasnet0_5', 'mnasnet0_75', 'mnasnet1_0', 'mnasnet1_3', 'mobilenet', 'mobilenet_v2', 'mobilenet_v3_large', 'mobilenet_v3_small', 'mobilenetv2', 'mobilenetv3', 'optical_flow', 'quantization', 'regnet', 'regnet_x_16gf', 'regnet_x_1_6gf', 'regnet_x_32gf', 'regnet_x_3_2gf', 'regnet_x_400mf', 'regnet_x_800mf', 'regnet_x_8gf', 'regnet_y_128gf', 'regnet_y_16gf', 'regnet_y_1_6gf', 'regnet_y_32gf', 'regnet_y_3_2gf', 'regnet_y_400mf', 'regnet_y_800mf', 'regnet_y_8gf', 'resnet', 'resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50', 'resnext101_32x8d', 'resnext101_64x4d', 'resnext50_32x4d', 'segmentation', 'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0', 'shufflenet_v2_x1_5', 'shufflenet_v2_x2_0', 'shufflenetv2', 'squeezenet', 'squeezenet1_0', 'squeezenet1_1', 'swin_b', 'swin_s', 'swin_t', 'swin_transformer', 'swin_v2_b', 'swin_v2_s', 'swin_v2_t', 'vgg', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'video', 'vision_transformer', 'vit_b_16', 'vit_b_32', 'vit_h_14', 'vit_l_16', 'vit_l_32', 'wide_resnet101_2', 'wide_resnet50_2']\n"
     ]
    }
   ],
   "source": [
    "# load pretrained model\n",
    "from torchvision import models\n",
    "print(dir(models))\n",
    "alexnet = models.AlexNet()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
